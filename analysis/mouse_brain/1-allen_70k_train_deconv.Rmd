---
title: "allen70k_mouse_brain_merge"
author: "Marc Elosua-Bayes"
date: "3/27/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
In this markdown we're gonna check how well we can deconvolute two saggital mouse brain sections with a ~75k cell dataset. This scRNAseq dataset was obtained form the Allen institute and can be downloaded through their [portal](https://portal.brain-map.org/atlases-and-data/rnaseq).

**RNA-Seq Data Summary**
Our goal is to quantify the diversity of cell types in the adult mouse brain using large-scale single-cell transcriptomics. Towards that goal, we have generated a dataset that includes close to 75,000 single cells from multiple cortical areas and the hippocampus. Samples were collected from fine dissections of brain regions from male and female mice. For most brain regions, we isolated labeled cells from pan-GABAergic, pan-glutamatergic, and pan-neuronal transgenic lines. For primary visual cortex (VISp) and anterolateral motor cortex (ALM), we sampled additional cells using driver lines that label more specific and rare types. To investigate the correspondence between transcriptomic types and neuronal projection properties, we collected cells labeled from retrograde injections for select combinations of target injection sites and dissection regions. Labeled cells were collected by fluorescence activated sorting (FACS) of single cells. We also collected cells without fluorescent label to sample non-neuronal cell types. Isolated single cells were processed for RNA sequencing using SMART-Seq v4. This dataset reveals the molecular architecture of the neocortex and hippocampal formation, with a wide range of shared and unique cell types across areas. It provides the basis for comparative studies of cellular diversity in development, evolution, and diseases. 

Additional RNA-Seq data generated as part of the Brain Initiative Cell Census Network (BICCN) is available as part of the Brain Cell Data Center (BCDC) portal.


## Libraries
```{r}
library(Seurat)
library(ggplot2)
library(dplyr)
library(purrr)
library(SPOTlight)
library(NMF)
library(nnls)
library(scrattch.io)
```

## Paths
```{r}
tech <- "sc"
tissue <- "allen_ref_70k"
dwn_smplng <- "both"
org <- "mm"
source("misc/paths_vrs.R")
seed_id <- 123
set.seed(seed_id)
```

## Set common parameters
```{r}
clust_vr <- "subclass_label"
cl_n <- 100
method <- "nsNMF"
transf <- "uv"
hvg <- 3000
FC <- 1
pct1 <- 0.9
date <- Sys.Date()

id_nmf <- sprintf("cln-%s_transf-%s_method-%s_hvg-%s_FC-%s_pct1-%s_seed-%s", 
                  cl_n, transf, method, hvg, FC, pct1, seed_id)
data_dir <- "data/MusMusculus/allen_reference"
options(stringsAsFactors = FALSE)


library(RColorBrewer)
n <- 60
qual_col_pals <- brewer.pal.info[brewer.pal.info$category == 'qual',]
col_vector <- unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
```

## Load data
### scRNAseq-
#### Load data 70k and convert to Seurat object
~76k cells are present in the dataset, refer to **scrattch.io** package on how to load the data.
```{r eval = FALSE}
tome <- sprintf("%s/transcrip.tome", data_dir)
# t_exon Contains the (row, column) matrix of read counts obtained for each (gene, cell) based on alignment to exons.
sample_name <- read_tome_sample_names(tome)  
gene_name <- read_tome_gene_names(tome)

exons <- read_tome_dgCMatrix(tome,"data/t_exon") # (or data/exon)
rownames(exons) <- gene_name
colnames(exons) <- sample_name

metadata <- readr::read_csv(file = sprintf("%s/sample-annotations.zip", data_dir)) %>% 
  tibble::column_to_rownames(var = "sample_name")

allen_ref_70k <- Seurat::CreateSeuratObject(counts = exons, 
                                            project = "allen_ref", 
                                            assay = "RNA", 
                                            meta.data = metadata)
```

Scale and normalize the data
```{r}
allen_ref_70k <- Seurat::SCTransform(object = allen_ref_70k, ncells = 3000)

saveRDS(object = allen_ref_70k, file = "data/MusMusculus/allen_reference/allen_ref_70k_processed.RDS")
allen_ref_70k <- readRDS(file = "data/MusMusculus/allen_reference/allen_ref_70k_processed.RDS")
```

Get cluster markers so we can downsample since it is a very large dataset.
```{r}
Seurat::Idents(object = allen_ref_70k) <- allen_ref_70k@meta.data[, clust_vr]
cluster_markers_all <- Seurat::FindAllMarkers(object = allen_ref_70k, 
                                              verbose = TRUE, 
                                              only.pos = TRUE,
                                              assay = "SCT",
                                              slot = "data", 
                                              min.pct = 0.9,
                                              max.cells.per.ident = 100)

saveRDS(object = cluster_markers_all, file = "data/MusMusculus/allen_reference/markers_allen_ref_70k.RDS")
cluster_markers_all <- readRDS(file = "data/MusMusculus/allen_reference/markers_allen_ref_70k.RDS")
```

### Downsampling + Data preprocessing
```{r}
cluster_markers_filt <- cluster_markers_all %>% 
  filter(avg_logFC > FC & pct.1 > pct1)

cluster_markers_filt %>% 
  count(cluster) %>% 
  data.frame()

cluster_markers_filt %>% filter(cluster == "Astro")
table(unique(cluster_markers_all$cluster) %in% unique(cluster_markers_filt$cluster))
```
As we can see all the cell types still have markers after filtering.

```{r}
dim(allen_ref_70k)
allen_ref_70k_down <- downsample_se_obj(se_obj = allen_ref_70k,
                                        clust_vr = clust_vr,
                                        cluster_markers = cluster_markers_filt, 
                                        cl_n = cl_n, 
                                        hvg = hvg)
dim(allen_ref_70k_down)

saveRDS(object = allen_ref_70k_down, 
        file = sprintf("data/MusMusculus/allen_reference/allen_ref_70k_downsampled_%s_new.RDS",
                       id_nmf))
rm(allen_ref_70k)

allen_ref_70k_down <- readRDS(file = sprintf("data/MusMusculus/allen_reference/allen_ref_70k_downsampled_%s_new.RDS",
                       id_nmf))
# allen_ref_70k_down <- readRDS(file = sprintf("data/MusMusculus/allen_reference/allen_ref_70k_downsampled_%s_test.RDS",
#                        id_nmf))

```

### Spatial data
We are going to use spatial data provided by 10x which can be downloaded [here](https://support.10xgenomics.com/spatial-gene-expression/datasets/). We have [posterior](https://support.10xgenomics.com/spatial-gene-expression/datasets/1.0.0/V1_Mouse_Brain_Sagittal_Posterior) and [anterior](https://support.10xgenomics.com/spatial-gene-expression/datasets/1.0.0/V1_Mouse_Brain_Sagittal_Anterior) saggital slices available.
Once the file is downloaded be sure to change the filename of *V1_Mouse_Brain_Sagittal_Anterior_filtered_feature_bc_matrix.h5* to *filtered_feature_bc_matrix.h5*, the latter is the name spaceranger outputs this file and it looks for it, also need to untar the compressed files .

#### Anterior slice
```{r}
anterior <- Seurat::Load10X_Spatial(data.dir = "data/MusMusculus/sag_ant_1",
                            assay = "Spatial",
                            slice = "Anterior",
                            filter.matrix = TRUE,
                            to.upper = FALSE)

anterior$slice <- "Anterior"
anterior <- Seurat::SCTransform(anterior, assay = "Spatial", verbose = TRUE)
```


#### Posterior slice
```{r}
posterior <- Seurat::Load10X_Spatial(data.dir = "data/MusMusculus/sag_post_1",
                            assay = "Spatial",
                            slice = "Posterior",
                            filter.matrix = TRUE,
                            to.upper = FALSE)

posterior$slice <- "Posterior"
posterior <- Seurat::SCTransform(posterior, assay = "Spatial", verbose = TRUE)
```

#### Merging slices
```{r}
brain <- merge(anterior, posterior)

Seurat::DefaultAssay(brain) <- "SCT"
Seurat::VariableFeatures(brain) <- c(Seurat::VariableFeatures(anterior),
                                           Seurat::VariableFeatures(posterior))
brain <- Seurat::RunPCA(brain, verbose = FALSE)
Seurat::ElbowPlot(object = brain, ndims = 50)
brain <- Seurat::FindNeighbors(brain, dims = 1:40)
brain <- Seurat::FindClusters(brain, verbose = FALSE)
brain <- Seurat::RunUMAP(brain, dims = 1:40)

saveRDS(object = brain,
        file = sprintf("%s/%s/brain1_processed.RDS", an_mouse, robj_dir))
brain <- readRDS(sprintf("%s/%s/brain1_processed.RDS", an_mouse, robj_dir))
```

Visualization of the merged slices
```{r}
Seurat::DimPlot(brain,
                reduction = "umap",
                group.by = c("ident", "slice"))

Seurat::SpatialDimPlot(brain)
# Seurat::SpatialFeaturePlot(object = brain, features = "Cplx3")
```

## Spatial Deconvolution
### Train NMF model
```{r}
start_time <- Sys.time()
nmf_mod_ls <- train_nmf(cluster_markers = cluster_markers_filt, 
                        se_sc = allen_ref_70k_down, 
                        mtrx_spatial = brain@assays$Spatial@counts, 
                        ntop = NULL, 
                        transf = transf, 
                        clust_vr = clust_vr, 
                        method = method)

tot_time <- difftime(time1 = Sys.time(), time2 =start_time , units = "mins")
tot_time

saveRDS(nmf_mod_ls,
        sprintf("nmf_mod_ls_%s_%s_new.RDS", id_comp, id_nmf))

# nmf_mod_ls <- readRDS(file = sprintf("nmf_mod_ls_%s_%s_new.RDS", id_comp, id_nmf))
nmf_mod <- nmf_mod_ls[[1]]
```

Extract matrices form the model:
```{r}
# get matrix W
w <- basis(nmf_mod)
dim(w)

# get matrix H
h <- coef(nmf_mod)
dim(h)
```

```{r}
rownames(h) <- paste("Topic", 1:nrow(h), sep = "_")
topic_profile_plts <- dot_plot_profiles_fun(h = h,
                      train_cell_clust = nmf_mod_ls[[2]], 
                      clust_vr = clust_vr)
topic_profile_plts[[2]] + theme(axis.text.x = element_text(angle = 90))

# topic_profile_plts[[2]] + theme(axis.text.x = element_blank(),
#                                 axis.text.y = element_blank(),
#                                 axis.title = element_blank())
```

### Spot Deconvolution

```{r}
# Extract count matrix
spot_counts <- brain@assays$Spatial@counts

# Subset to genes used to train the model
spot_counts <- spot_counts[rownames(spot_counts) %in% rownames(w), ]
```

#### Get mixture composition
Run test spots through the basis to get the pertinent coefficients. To do this for every spot we are going to set up a system of linear equations where we need to find the coefficient, we will use non-negative least squares to determine the best coefficient fit. 
```{r}
ct_topic_profiles <- topic_profile_per_cluster_nmf(h = h,
                              train_cell_clust = nmf_mod_ls[[2]],
                              clust_vr = clust_vr)

decon_mtrx <- mixture_deconvolution_nmf(nmf_mod = nmf_mod,
                                        clust_vr = clust_vr,
                                        mixture_transcriptome = spot_counts,
                                        transf = transf,
                                        reference_profiles = ct_topic_profiles,
                                        min_cont = 0.09)
saveRDS(decon_mtrx,
        sprintf("decon_mtrx_%s_%s.RDS", id_comp, id_nmf))

# decon_mtrx <- readRDS(file = sprintf("decon_mtrx_%s_%s.RDS", id_comp, id_nmf))
```

